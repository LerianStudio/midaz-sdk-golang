package concurrent // import "github.com/LerianStudio/midaz-sdk-golang/v2/pkg/concurrent"

Package concurrent provides utilities for working with concurrent operations in
the Midaz SDK.

This package implements common concurrency patterns such as worker pools,
rate limiters, and batch operations to help users work efficiently with the
Midaz API.

Use Cases:

 1. High-Volume Payment Processing: When processing thousands of payment
    transactions, use WorkerPool with appropriate concurrency settings to
    maximize throughput while respecting API limits:

    ```go // Process 10,000 payments concurrently with controlled parallelism
    payments := fetchPendingPayments() // e.g., 10,000 payments

    results := concurrent.WorkerPool(ctx, payments, func(ctx
    context.Context, payment Payment) (PaymentResult, error) { return
    processPayment(ctx, payment) }, concurrent.WithWorkers(20),
    // Use 20 concurrent workers concurrent.WithBufferSize(100), // Buffer
    100 items concurrent.WithRateLimit(1000), // Max 1000 ops/second
    concurrent.WithUnorderedResults(), // Process in any order )

    // Handle results for _, result := range results { if result.Error
    != nil { logPaymentError(result.Item, result.Error) } else {
    recordSuccessfulPayment(result.Item, result.Value) } } ```

 2. Batch Account Updates: When performing batch updates to many accounts,
    use the Batch function to group operations efficiently:

    ```go // Update 5,000 accounts in batches of 50 accounts :=
    fetchAccountsToUpdate() // e.g., 5,000 accounts

    results := concurrent.Batch(ctx, accounts, 50, func(ctx context.Context,
    batch []Account) ([]UpdateResult, error) { // API call that can process up
    to 50 accounts at once return client.BulkUpdateAccounts(ctx, batch) }, )

    // Process results... ```

 3. API Rate Limiting: When calling an API with strict rate limits, use
    RateLimiter to prevent exceeding those limits and triggering throttling or
    blocks:

    ```go // Create a rate limiter for an API limited to 100 requests per second
    rateLimiter := concurrent.NewRateLimiter(100, 20) defer rateLimiter.Stop()

    // In your request function func makeAPIRequest(ctx context.Context,
    req Request) (Response, error) { // Wait for a rate limiter token before
    proceeding if err := rateLimiter.Wait(ctx); err != nil { return Response{},
    err }

    // Now make the API call, knowing it respects rate limits return
    client.SendRequest(ctx, req) } ```

Package concurrent provides utilities for working with concurrent operations in
the Midaz SDK.

This file contains high-level helper functions built on top of the core
concurrent primitives, offering ready-to-use solutions for common financial
operations: - Parallel account fetching and creation - Concurrent transaction
processing - Generic resource fetching - Mixed operation coordination

These helpers are designed to simplify common concurrency patterns in financial
applications without requiring detailed knowledge of the underlying concurrency
mechanisms.

Package concurrent provides utilities for parallel processing and batch
operations.

var ErrCircuitOpen = errors.New("circuit breaker open")
func BatchCreateAccounts(ctx context.Context, ...) ([]*models.Account, error)
func BulkFetchResourceMap[K comparable, V any](ctx context.Context, fetchFn func(ctx context.Context, id K) (V, error), ...) (map[K]V, error)
func FetchAccountsInParallel(ctx context.Context, ...) (map[string]*models.Account, error)
func ForEach[T any](ctx context.Context, items []T, fn func(ctx context.Context, item T) error, ...) error
func ProcessTransactionsInParallel(ctx context.Context, ...) ([]*models.Transaction, []error)
func RunConcurrentOperations(ctx context.Context, operations []func(context.Context) error) []error
type CircuitBreaker struct{ ... }
    func NewCircuitBreaker(failureThreshold, successThreshold int, openTimeout time.Duration) *CircuitBreaker
    func NewCircuitBreakerNamed(name string, failureThreshold, successThreshold int, openTimeout time.Duration) *CircuitBreaker
type DefaultJSONMarshaler struct{}
type HTTPBatchOption func(*HTTPBatchOptions) error
    func WithBatchContinueOnError(continueOnError bool) HTTPBatchOption
    func WithBatchRetryBackoff(backoff time.Duration) HTTPBatchOption
    func WithBatchRetryCount(count int) HTTPBatchOption
    func WithBatchTimeout(timeout time.Duration) HTTPBatchOption
    func WithBatchWorkers(workers int) HTTPBatchOption
    func WithHighReliabilityBatch() HTTPBatchOption
    func WithHighThroughputBatch() HTTPBatchOption
    func WithLowLatencyBatch() HTTPBatchOption
    func WithMaxBatchSize(size int) HTTPBatchOption
type HTTPBatchOptions struct{ ... }
    func DefaultHTTPBatchOptions() *HTTPBatchOptions
type HTTPBatchProcessor struct{ ... }
    func NewHTTPBatchProcessor(client *http.Client, baseURL string, opts ...HTTPBatchOption) *HTTPBatchProcessor
type HTTPBatchProcessorWithRetry struct{ ... }
    func NewHTTPBatchProcessorWithRetry(client *http.Client, baseURL string, opts ...HTTPBatchOption) (*HTTPBatchProcessorWithRetry, error)
type HTTPBatchRequest struct{ ... }
type HTTPBatchResponse struct{ ... }
type HTTPBatchResult struct{ ... }
type JSONMarshaler interface{ ... }
type PoolOption func(*poolOptions)
    func WithBufferSize(size int) PoolOption
    func WithRateLimit(operationsPerSecond int) PoolOption
    func WithUnorderedResults() PoolOption
    func WithWaitGroup(wg *sync.WaitGroup) PoolOption
    func WithWorkers(workers int) PoolOption
type RateLimiter struct{ ... }
    func NewRateLimiter(opsPerSecond int, maxBurst int) *RateLimiter
type Result[T, R any] struct{ ... }
    func Batch[T, R any](ctx context.Context, items []T, batchSize int, ...) []Result[T, R]
    func WorkerPool[T, R any](ctx context.Context, items []T, workFn WorkFunc[T, R], opts ...PoolOption) []Result[T, R]
type WorkFunc[T, R any] func(ctx context.Context, item T) (R, error)
